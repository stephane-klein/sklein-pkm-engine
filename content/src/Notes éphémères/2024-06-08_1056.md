---
tags:
  - hardware
  - NPU
  - CPU
  - AMD
  - MachineLearning
  - Inference
  - tops
nanoid: zxf5hms1nozd
type: fleeting_note
created_at: 2024-06-08 10:56
---

En lisant [ceci](https://en.wikipedia.org/wiki/AI_accelerator) :

> AI accelerators are used in mobile devices, such as neural processing units (NPUs) in Apple iPhones, AMD Laptops or Huawei cellphones, and personal computers such as Apple silicon Macs, to cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform.

#JaiDécouvert que [[AMD XDNA]] semble être l'architecture des puces [[NPU]] de [[AMD]].

Je lis [ici](https://en.wikipedia.org/wiki/Ryzen#Ryzen_AI) que [[Ryzen AI]] est le nom commercial du matériel [[AMD]] qui implémente l'architecture [[AMD XDNA|XDNA]].

La première puce qui intégrèe [[AMD XDNA]] est le [Ryzen 7040](https://en.wikipedia.org/wiki/Ryzen#Mobile_6) sorti 2023.

Dans [cet article](https://en.wikipedia.org/wiki/List_of_AMD_Ryzen_processors#Phoenix_mobile) je lis :

- Des puces de la série Ryzen 7040 intègrent des NPU à 10 TOPS
- Des puces de la série Ryzen 8000 intègrent des NPU à 16 TOPS
- Des puces de la série Ryzen AI 300 intègrent des NPU à 50 TOPS
