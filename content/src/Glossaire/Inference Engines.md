---
aliases:
  - Inference Engine (comme LLama.cpp)
tags:
  - vocabulaire
  - llm
  - Inference
nanoid: qg2adjzg2ps5
type: evergreen_note
---
Nom alternatifs à "Inference Engines" :

- Exécuteur d'inférence (Inference runtime) ;
- Bibliothèque d'inférence.

Personnellement, j'ai décidé d'utiliser le terme [[Inference Engines]].

Update du 2024-06-08 : suite à [[2024-06-08_1035]], pour éviter la confusion, #JaiDécidé d'utiliser à l'avenir le terme **"Inference Engine (comme LLama.cpp)"**.

Exemples de "Inference Engines" :

- [[Llama.cpp]]
- [llm](https://github.com/rustformers/llm) - Large Language Models for Everyone, in Rust.
- https://github.com/karpathy/llm.c - LLM training in simple, raw C/CUDA ([from](https://twitter.com/karpathy/status/1777427944971083809))
